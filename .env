# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=  # Optional, if authentication is enabled

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=30

# --- Model Definitions ---
# General Purpose
LLAMA3_2_LATEST_NAME=llama3.2:latest
LLAMA3_2_LATEST_PROVIDER=ollama
LLAMA3_2_LATEST_CAPABILITIES="general_conversation,analysis,summarization"
LLAMA3_2_LATEST_CONTEXT_LENGTH=4096  # You'll need to look this up!
LLAMA3_2_LATEST_TEMPERATURE=0.7
LLAMA3_2_LATEST_TOP_P=0.9
LLAMA3_2_LATEST_TOP_K=40

LLAMA3_2_1B_NAME=llama3.2:1b
LLAMA3_2_1B_PROVIDER=ollama
LLAMA3_2_1B_CAPABILITIES="general_conversation" # Adjust as needed
LLAMA3_2_1B_CONTEXT_LENGTH=4096 # Assume same as other llama3.2, but verify
LLAMA3_2_1B_TEMPERATURE=0.7
LLAMA3_2_1B_TOP_P=0.9
LLAMA3_2_1B_TOP_K=40

MISTRAL_SMALL_LATEST_NAME=mistral-small:latest
MISTRAL_SMALL_LATEST_PROVIDER=ollama
MISTRAL_SMALL_LATEST_CAPABILITIES="general_conversation,analysis,summarization"
MISTRAL_SMALL_LATEST_CONTEXT_LENGTH=8192
MISTRAL_SMALL_LATEST_TEMPERATURE=0.7
MISTRAL_SMALL_LATEST_TOP_P=0.9
MISTRAL_SMALL_LATEST_TOP_K=40

# Code Generation
DEEPSEEK_R1_32B_NAME=deepseek-r1:32b
DEEPSEEK_R1_32B_PROVIDER=ollama
DEEPSEEK_R1_32B_CAPABILITIES="code_generation,code_explanation,debugging,technical_writing"
DEEPSEEK_R1_32B_CONTEXT_LENGTH=16384 # Example, look this up
DEEPSEEK_R1_32B_TEMPERATURE=0.5
DEEPSEEK_R1_32B_TOP_P=0.95
DEEPSEEK_R1_32B_TOP_K=50

QWEN2_5_CODER_0_5B_NAME=qwen2.5-coder:0.5b
QWEN2_5_CODER_0_5B_PROVIDER=ollama
QWEN2_5_CODER_0_5B_CAPABILITIES="code_generation"
QWEN2_5_CODER_0_5B_CONTEXT_LENGTH=2048 # Example, look this up
QWEN2_5_CODER_0_5B_TEMPERATURE=0.5
QWEN2_5_CODER_0_5B_TOP_P=0.95
QWEN2_5_CODER_0_5B_TOP_K=50

# --- Pair Definitions ---
# Peer-to-Peer (General)
PAIR1_MODEL1=LLAMA3_2_LATEST
PAIR1_MODEL2=MISTRAL_SMALL_LATEST

# Large vs. Small (Code)
PAIR2_MODEL1=DEEPSEEK_R1_32B
PAIR2_MODEL2=QWEN2_5_CODER_0_5B

# Specialized vs General
PAIR3_MODEL1=LLAMA3_2_LATEST
PAIR3_MODEL2=QWEN2_5_CODER_0_5B


# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=dialogllm.log

# Performance Monitoring
ENABLE_MONITORING=true
METRICS_COLLECTION_INTERVAL=60  # seconds
PERFORMANCE_THRESHOLD_MS=100    # Response time threshold